# ğŸ¤š DÃ©tection de Main LFPC avec MediaPipe

## ğŸ“‹ Vue d'ensemble

Ce module permet la dÃ©tection de main en temps rÃ©el via webcam et la comparaison avec les configurations LFPC (Langue franÃ§aise ParlÃ©e ComplÃ©tÃ©e).

## ğŸ› ï¸ Technologies utilisÃ©es

- **MediaPipe Hands** - DÃ©tection de 21 landmarks de la main
- **@mediapipe/camera_utils** - Gestion de la webcam
- **@mediapipe/drawing_utils** - Dessin des landmarks
- **React** - Interface utilisateur

## ğŸ“ Structure des fichiers

```
src/
â”œâ”€â”€ components/
â”‚   â””â”€â”€ HandDetection.jsx          # Composant principal de dÃ©tection
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useHandDetection.js        # Hook custom pour MediaPipe
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ lfpcMatcher.js             # Logique de comparaison LFPC
â””â”€â”€ app/
    â””â”€â”€ HandDetectionDemo.jsx      # Page de dÃ©monstration
```

## ğŸš€ Installation

Les dÃ©pendances MediaPipe ont dÃ©jÃ  Ã©tÃ© installÃ©es :

```bash
npm install @mediapipe/hands @mediapipe/camera_utils @mediapipe/drawing_utils
```

## ğŸ’» Utilisation

### Exemple basique

```jsx
import HandDetection from '../components/HandDetection';
import { SAMPLE_LFPC_CONFIGS } from '../utils/lfpcMatcher';

function MyComponent() {
  const handleConfigDetected = (config) => {
    console.log('Configuration dÃ©tectÃ©e:', config);
  };

  return (
    <HandDetection
      lfpcConfigs={SAMPLE_LFPC_CONFIGS}
      onConfigDetected={handleConfigDetected}
      showDebugInfo={true}
    />
  );
}
```

### Utilisation du hook `useHandDetection`

```jsx
import { useRef } from 'react';
import { useHandDetection } from '../hooks/useHandDetection';

function CustomComponent() {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);

  const { landmarks, isDetecting, handedness, startCamera, stopCamera } = 
    useHandDetection({
      videoRef: videoRef.current,
      canvasRef: canvasRef.current,
      onResults: (results) => {
        console.log('Landmarks:', results.landmarks);
        console.log('Main:', results.handedness);
      },
    });

  return (
    <div>
      <video ref={videoRef} />
      <canvas ref={canvasRef} />
      <button onClick={startCamera}>DÃ©marrer</button>
      <button onClick={stopCamera}>ArrÃªter</button>
    </div>
  );
}
```

### Comparaison avec configurations LFPC

```jsx
import { compareWithLFPCConfig } from '../utils/lfpcMatcher';

const lfpcConfigs = [
  {
    id: 1,
    description: "Main sous l'Å“il",
    voyelles: ["in", "eu", "un"],
    position_number: 1,
    reference_landmarks: [...], // 21 points de rÃ©fÃ©rence
  },
  // ... autres configurations
];

// Dans votre callback onResults
const match = compareWithLFPCConfig(landmarks, lfpcConfigs);

if (match) {
  console.log('Position:', match.description);
  console.log('Confiance:', match.confidence + '%');
  console.log('Voyelles:', match.voyelles);
}
```

## ğŸ“Š Format des donnÃ©es

### Landmarks MediaPipe

Chaque landmark contient :
```javascript
{
  x: 0.5,      // Position X normalisÃ©e (0-1)
  y: 0.3,      // Position Y normalisÃ©e (0-1)
  z: -0.1,     // Profondeur relative
}
```

21 landmarks au total :
- **0** : Poignet
- **1-4** : Pouce
- **5-8** : Index
- **9-12** : Majeur
- **13-16** : Annulaire
- **17-20** : Auriculaire

### Configuration LFPC

```javascript
{
  id: 1,
  description: "Main sous l'Å“il",
  voyelles: ["in", "eu", "un"],
  position_number: 1,
  reference_landmarks: [
    { x: 0.5, y: 0.3, z: -0.1 },
    // ... 20 autres points
  ],
  confidence: 85,  // AjoutÃ© aprÃ¨s comparaison
  distance: 0.023  // AjoutÃ© aprÃ¨s comparaison
}
```

## ğŸ¯ Algorithme de comparaison

L'algorithme utilise :

1. **Normalisation** : Les landmarks sont normalisÃ©s par rapport au poignet
2. **Points clÃ©s** : Focus sur 6 points importants (poignet + bout des doigts)
3. **Distance euclidienne** : Calcul de la distance 3D entre chaque point
4. **Score de confiance** : Conversion de la distance en pourcentage (0-100%)

```javascript
// Points clÃ©s utilisÃ©s pour la comparaison
const keyPoints = [0, 4, 8, 12, 16, 20];

// Seuil de confiance minimum
const MIN_CONFIDENCE = 30; // %
```

## ğŸ”§ Configuration MediaPipe

```javascript
hands.setOptions({
  maxNumHands: 1,              // DÃ©tecter une seule main
  modelComplexity: 1,          // 0=lite, 1=full (meilleur pour LFPC)
  minDetectionConfidence: 0.7, // Seuil de dÃ©tection
  minTrackingConfidence: 0.5,  // Seuil de suivi
});
```

## ğŸ“ Prochaines Ã©tapes

### 1. Enregistrer des landmarks de rÃ©fÃ©rence

CrÃ©er une interface pour enregistrer les positions LFPC :

```jsx
function RecordLandmarks() {
  const [recordedLandmarks, setRecordedLandmarks] = useState(null);

  const handleRecord = (landmarks) => {
    setRecordedLandmarks(landmarks);
    // Sauvegarder dans Supabase
    saveToSupabase(landmarks);
  };

  return (
    <HandDetection
      onConfigDetected={(config) => {
        // Enregistrer les landmarks actuels
        handleRecord(config.landmarks);
      }}
    />
  );
}
```

### 2. IntÃ©grer avec Supabase

Modifier la table `hand_positions` pour stocker les landmarks :

```sql
ALTER TABLE hand_positions 
ADD COLUMN reference_landmarks JSONB;

-- Exemple d'insertion
UPDATE hand_positions 
SET reference_landmarks = '[
  {"x": 0.5, "y": 0.3, "z": -0.1},
  ...
]'::jsonb
WHERE configuration_number = 1;
```

### 3. Charger depuis Supabase

```javascript
const loadLFPCConfigs = async () => {
  const { data, error } = await supabase
    .from('hand_positions')
    .select('*');

  if (data) {
    setLfpcConfigs(data.map(config => ({
      ...config,
      reference_landmarks: JSON.parse(config.reference_landmarks),
    })));
  }
};
```

### 4. AmÃ©liorer la prÃ©cision

- Enregistrer plusieurs exemples par configuration
- Calculer une moyenne des landmarks
- Ajouter des filtres de lissage temporel
- Ajuster les seuils de confiance

## ğŸ¨ Personnalisation

### Changer les couleurs des landmarks

Dans `useHandDetection.js`, fonction `drawHandLandmarks` :

```javascript
// Points clÃ©s en rouge
ctx.fillStyle = isKeyPoint ? '#FF0000' : '#00FF00';

// Connexions en vert
ctx.strokeStyle = '#00FF00';
```

### Ajuster la taille du canvas

```javascript
const camera = new Camera(videoRef, {
  onFrame: async () => { ... },
  width: 1280,  // Modifier ici
  height: 720,  // Modifier ici
});
```

## ğŸ› DÃ©pannage

### La webcam ne dÃ©marre pas

- VÃ©rifier les permissions du navigateur
- Utiliser HTTPS (requis pour getUserMedia)
- VÃ©rifier que la webcam n'est pas utilisÃ©e par une autre app

### Aucune main dÃ©tectÃ©e

- AmÃ©liorer l'Ã©clairage
- Placer la main plus prÃ¨s de la camÃ©ra
- RÃ©duire `minDetectionConfidence` dans les options

### Mauvaise prÃ©cision

- Enregistrer de meilleurs landmarks de rÃ©fÃ©rence
- Augmenter `modelComplexity` Ã  1
- Utiliser plus de points clÃ©s dans la comparaison

## ğŸ“š Ressources

- [MediaPipe Hands Documentation](https://google.github.io/mediapipe/solutions/hands.html)
- [Landmark Index Reference](https://google.github.io/mediapipe/solutions/hands.html#hand-landmark-model)
- [LFPC Wikipedia](https://fr.wikipedia.org/wiki/Langue_fran%C3%A7aise_parl%C3%A9e_compl%C3%A9t%C3%A9e)

## ğŸ¤ Contribution

Pour amÃ©liorer la dÃ©tection :

1. Enregistrer vos propres landmarks de rÃ©fÃ©rence
2. Tester avec diffÃ©rentes conditions d'Ã©clairage
3. Ajuster les seuils de confiance
4. Partager vos rÃ©sultats

## ğŸ“„ Licence

Ce module fait partie du projet KeepTalking - Application d'apprentissage LFPC.
